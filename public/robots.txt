# See http://www.robotstxt.org/robotstxt.html for documentation on how to use the robots.txt file
#
# To ban all spiders from the entire site uncomment the next two lines:
User-agent: *
Crawl-delay: 30
Disallow: /
Disallow: /users/sign_in$
Disallow: /?q=*
Disallow: /?f*
Disallow: /*?q=*
Disallow: /*?f*
Disallow: /catalog/opensearch
Disallow: /catalog/facet
Disallow: /catalog/range_limit
Disallow: /bookmarks
Disallow: /users
Disallow: /query_list

# Allow these cagents to crawl catalog
 User-agent: Googlebot
 User-agent: Googlebot-Image
 User-agent: bingbot
 User-agent: Slurp
 Disallow: /
 Allow: /catalog$
 Allow: /articles$
 Allow: /databases$
 Allow: /journals$
 Allow: /web_content$
 Allow: /catalog/advanced$
 Allow: /articles/advanced$
 Allow: /databases/advanced$
 Allow: /journals/advanced$
