# Catalog on Blacklight

A minimal Blacklight Application for exploring Temple University MARC data in preparation for migration to Alma.

[![View performance data on Skylight](https://badges.skylight.io/status/UMsaUKxxdxMC.svg)](https://oss.skylight.io/app/applications/UMsaUKxxdxMC)

## Getting started

### Install the Application
This only needs to happen the first time.

```bash
git clone git@github.com:tulibraries/tul_cob
cd tul_cob
bundle install
cp config/secrets.yml.example config/secrets.yml
```

We also need to configure the application with our Alma and Primo apikey for development work on the Bento box or User account. Start by copying the example alma and bento config files.

```bash
cp config.alma.yml.example config/alma.yml
cp config/bento.yml.example config/bento.yml
```

Then edit them adding in the apikeys for our application specified in our Ex Libris Developer Network.

```bash
bundle exec rails db:migrate
```


### Start the Application

We need to run two commands in separate terminal windows in order to start the application.
* In the first terminal window, start solr with run
```bash
bundle exec solr_wrapper
```
* In the second terminal window, start Puma, the rails application server
```bash
bundle exec rails server
```

* Alternatively, use docker if it is available locally.
```bash
rake docker:up
```

### Start the Application with some sample data for Development

If you want to quickly get the application running for development with a minimal
set of example data, you can run

`bundle exec rake server`

It will start up solr_wrapper, ingest a few hundred sample records, and start the rails server.


### Preparing Alma Data

For the marcxml sample data that has been generated by Alma and exported by FTP, it needs to be processed before committing it to the sample_data folder:

```bash

./bin/massage.sh sample_data/alma_bibs.xml

```

### Ingest the sample Alma data with Traject

Now you are ready to ingest:

The simplest way to ingest a marc data file into your local solr is with the `ingest` rake task. Called with no parameters, it will ingest the data at [sample_data/alma_bibs.xml](https://github.com/tulibraries/tul_cob/blob/master/sample_data/alma_bibs.xml)


```bash
bundle exec rake ingest
```

You can also pass in ther path to a separate file you would like to ingest as a parameter

```bash
bundle exec rake ingest[/some/other/path.xml]
```


Under the hood, that command uses [traject](https://github.com/traject/traject), with hard coded defaults. If you need to override a default to ingest your data, You can call traject directly: 

```bash
bundle exec traject -s solr.url=http://somehere/solr -c app/models/traject_indexer.rb sample_data/alma_bibs.xml
```

If using docker, then ingest using `docker-compose exec app traject -c app/models/traject_indexer.rb sample_data/alma_bibs.xml`.

## Importing from Alma

In order to import from Alma directly execute the following Rake tasks. Harvest may be supplied with
an optional date/time ranges in ISO8901 format and enclosed in brackets. You may provide `from` and/or `ta`o
date/times. You may not provide only a `to` date/time

```bash
bundle exec rake fortytu:oai:harvest[from,to]
bundle exec rake fortytu:oai:conform_all
bundle exec rake fortytu:oai:ingest_all
```

## Running the Tests


`bundle exec rake ci`

This will spin up a test solr instance, import a few hundred records, and run the test suite.
